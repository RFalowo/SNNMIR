
Epoch 0:   0%|          | 0/998 [00:00<?, ?it/s] 25562.322265625 torch.Size([1293, 1, 40]) tensor(0.1909, device='mps:0') tensor(0.8920, device='mps:0')
INFO:pytorch_lightning.callbacks.model_summary:
  | Name       | Type                     | Params
--------------------------------------------------------
0 | S1         | Sequential               | 2.0 K
1 | rsnn_block | LinearRecurrentContainer | 4.7 K
2 | output     | Sequential               | 49
3 | S2         | IFNode                   | 0
--------------------------------------------------------
6.7 K     Trainable params
0         Non-trainable params
6.7 K     Total params
0.027     Total estimated model params size (MB)
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.

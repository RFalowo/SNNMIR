INFO:pytorch_lightning.callbacks.model_summary:
  | Name       | Type                     | Params
--------------------------------------------------------
0 | S1         | IFNode                   | 0
1 | rsnn_block | LinearRecurrentContainer | 3.2 K
2 | output     | Sequential               | 41
3 | S2         | IFNode                   | 0
--------------------------------------------------------
3.3 K     Trainable params
0         Non-trainable params
3.3 K     Total params
0.013     Total estimated model params size (MB)
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.
  warnings.warn(







































































































































































































Epoch 9:  95%|█████████▌| 19/20 [00:52<00:02,  0.36it/s, v_num=7ejp]

Epoch 9: 100%|██████████| 20/20 [00:55<00:00,  0.36it/s, v_num=7ejp]
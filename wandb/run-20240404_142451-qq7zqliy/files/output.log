INFO:pytorch_lightning.callbacks.model_summary:
  | Name       | Type                     | Params
--------------------------------------------------------
0 | S1         | IFNode                   | 0
1 | rsnn_block | LinearRecurrentContainer | 3.2 K
2 | output     | Sequential               | 41
3 | S2         | IFNode                   | 0
--------------------------------------------------------
3.3 K     Trainable params
0         Non-trainable params
3.3 K     Total params
0.013     Total estimated model params size (MB)
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.
  warnings.warn(
Epoch 0:   0%|          | 0/20 [00:00<?, ?it/s]
/Users/remi/Documents/PhD/SpikingExp/spikingjelly_beat_detection.py:89: MatplotlibDeprecationWarning: Support for FigureCanvases without a required_interactive_framework attribute was deprecated in Matplotlib 3.6 and will be removed two minor releases later.
  plt.figure(figsize=(10, 4))
WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.

Epoch 0:   5%|▌         | 1/20 [00:04<01:31,  0.21it/s, v_num=qliy]

Epoch 0:  10%|█         | 2/20 [00:07<01:07,  0.27it/s, v_num=qliy]


















Epoch 0: 100%|██████████| 20/20 [00:55<00:00,  0.36it/s, v_num=qliy]

Epoch 1:   5%|▌         | 1/20 [00:03<01:00,  0.31it/s, v_num=qliy]
wandb: WARNING Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
wandb: WARNING (User provided step: 0 is less than current step: 2. Dropping entry: {'Beat Detection Plot': {'_type': 'images/separated', 'width': 1000, 'height': 400, 'format': 'png', 'count': 1, 'filenames': ['media/images/Beat Detection Plot_2_4d04d2b9250d041c260f.png'], 'captions': ['Beat Detection (Sample 0)']}, '_timestamp': 1712237152.0979998}).

Epoch 1:  10%|█         | 2/20 [00:06<00:54,  0.33it/s, v_num=qliy]



Epoch 1:  25%|██▌       | 5/20 [00:15<00:45,  0.33it/s, v_num=qliy]
















Epoch 2:   5%|▌         | 1/20 [00:02<00:51,  0.37it/s, v_num=qliy]

Epoch 2:  10%|█         | 2/20 [00:06<00:55,  0.32it/s, v_num=qliy]

Epoch 2:  15%|█▌        | 3/20 [00:08<00:50,  0.34it/s, v_num=qliy]
WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
wandb: WARNING (User provided step: 0 is less than current step: 2. Dropping entry: {'Beat Detection Plot': {'_type': 'images/separated', 'width': 1000, 'height': 400, 'format': 'png', 'count': 1, 'filenames': ['media/images/Beat Detection Plot_2_4d04d2b9250d041c260f.png'], 'captions': ['Beat Detection (Sample 0)']}, '_timestamp': 1712237205.699501}).


















Epoch 3:   5%|▌         | 1/20 [00:03<00:57,  0.33it/s, v_num=qliy]

Epoch 3:  10%|█         | 2/20 [00:05<00:53,  0.34it/s, v_num=qliy]

Epoch 3:  15%|█▌        | 3/20 [00:08<00:50,  0.34it/s, v_num=qliy]


Epoch 3:  25%|██▌       | 5/20 [00:14<00:42,  0.36it/s, v_num=qliy]
wandb: WARNING (User provided step: 0 is less than current step: 3. Dropping entry: {'Beat Detection Plot': {'_type': 'images/separated', 'width': 1000, 'height': 400, 'format': 'png', 'count': 1, 'filenames': ['media/images/Beat Detection Plot_3_4d04d2b9250d041c260f.png'], 'captions': ['Beat Detection (Sample 0)']}, '_timestamp': 1712237260.6308942}).
wandb: WARNING (User provided step: 1 is less than current step: 3. Dropping entry: {'Beat Detection Plot': {'_type': 'images/separated', 'width': 1000, 'height': 400, 'format': 'png', 'count': 1, 'filenames': ['media/images/Beat Detection Plot_3_47a77e26c89d89ee8bee.png'], 'captions': ['Beat Detection (Sample 1)']}, '_timestamp': 1712237263.495295}).
















Epoch 4:   5%|▌         | 1/20 [00:02<00:52,  0.36it/s, v_num=qliy]

Epoch 4:  10%|█         | 2/20 [00:05<00:51,  0.35it/s, v_num=qliy]
WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
wandb: WARNING (User provided step: 0 is less than current step: 3. Dropping entry: {'Beat Detection Plot': {'_type': 'images/separated', 'width': 1000, 'height': 400, 'format': 'png', 'count': 1, 'filenames': ['media/images/Beat Detection Plot_3_4d04d2b9250d041c260f.png'], 'captions': ['Beat Detection (Sample 0)']}, '_timestamp': 1712237313.953166}).

Epoch 4:  15%|█▌        | 3/20 [00:08<00:48,  0.35it/s, v_num=qliy]





Epoch 4:  40%|████      | 8/20 [00:21<00:32,  0.37it/s, v_num=qliy]













Epoch 5:   5%|▌         | 1/20 [00:03<01:06,  0.29it/s, v_num=qliy]
WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.


Epoch 5:  15%|█▌        | 3/20 [00:09<00:52,  0.32it/s, v_num=qliy]


Epoch 5:  25%|██▌       | 5/20 [00:14<00:44,  0.34it/s, v_num=qliy]
wandb: WARNING (User provided step: 0 is less than current step: 4. Dropping entry: {'Beat Detection Plot': {'_type': 'images/separated', 'width': 1000, 'height': 400, 'format': 'png', 'count': 1, 'filenames': ['media/images/Beat Detection Plot_4_4d04d2b9250d041c260f.png'], 'captions': ['Beat Detection (Sample 0)']}, '_timestamp': 1712237366.4861288}).
wandb: WARNING (User provided step: 1 is less than current step: 4. Dropping entry: {'Beat Detection Plot': {'_type': 'images/separated', 'width': 1000, 'height': 400, 'format': 'png', 'count': 1, 'filenames': ['media/images/Beat Detection Plot_4_47a77e26c89d89ee8bee.png'], 'captions': ['Beat Detection (Sample 1)']}, '_timestamp': 1712237369.229613}).
















Epoch 6:   5%|▌         | 1/20 [00:02<00:53,  0.35it/s, v_num=qliy]

Epoch 6:  10%|█         | 2/20 [00:05<00:52,  0.35it/s, v_num=qliy]
WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
wandb: WARNING (User provided step: 0 is less than current step: 4. Dropping entry: {'Beat Detection Plot': {'_type': 'images/separated', 'width': 1000, 'height': 400, 'format': 'png', 'count': 1, 'filenames': ['media/images/Beat Detection Plot_4_4d04d2b9250d041c260f.png'], 'captions': ['Beat Detection (Sample 0)']}, '_timestamp': 1712237419.657953}).

Epoch 6:  10%|█         | 2/20 [00:05<00:52,  0.35it/s, v_num=qliy]<built-in method sum of Tensor object at 0x139361c70>
<built-in method sum of Tensor object at 0x139361950>
<built-in method sum of Tensor object at 0x139361950>
/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:44: Detected KeyboardInterrupt, attempting graceful shutdown...
Traceback (most recent call last):
  File "/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py", line 2195, in <module>
    main()
  File "/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py", line 2177, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py", line 1489, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File "/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py", line 1496, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/Users/remi/Documents/PhD/SpikingExp/spikingjelly_beat_detection.py", line 166, in <module>
    main()
  File "/Users/remi/Documents/PhD/SpikingExp/spikingjelly_beat_detection.py", line 162, in main
    trainer.fit(model)
  File "/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 754, in test
    return call._call_and_handle_interrupt(
  File "/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 794, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 937, in _run
    _verify_loop_configurations(self)
  File "/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py", line 42, in _verify_loop_configurations
    __verify_eval_loop_configuration(model, "test")
  File "/Users/remi/Documents/PhD/NLP/SpikingExp/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py", line 110, in __verify_eval_loop_configuration
    raise MisconfigurationException(f"No `{step_name}()` method defined to run `Trainer.{trainer_method}`.")
